# 🗓️ KDT Woongjin 학습 및 프로젝트 기록
---

## 🚀 프로젝트 타임라인 (Timeline)

### 📂 [2026-01-06] YouTube 트렌드 분석 및 시각화 시스템
*   **프로젝트 위치**: `ai/api/`, `ai/view/`
*   **목적**: 특정 키워드에 대한 YouTube 영상 데이터를 수집하고, 일별 통계 분석 및 시각화 대시보드를 제공하여 트렌드를 파악합니다.
*   **동작 원리 및 순서**:
    1.  **데이터 수집 (`youtube_search.py`)**: YouTube Data API v3를 활용, 페이지네이션을 처리하며 최대 1,000건의 영상 정보(제목, 날짜, 채널명)를 가져옵니다.
    2.  **상세 정보 매핑**: 수집된 각 영상 ID를 기반으로 별도의 API 호출을 통해 조회수(View Count) 데이터를 확보합니다.
    3.  **데이터 가공**: Pandas를 사용하여 날짜별 업로드 수와 조회수 총합을 집계하고 CSV 형식(`utf-8-sig`)으로 저장합니다.
    4.  **시각화 (`dashboard.py`, `viewer.py`)**: Tkinter와 Matplotlib을 연동하여 수집된 CSV를 불러와 일별 트렌드 차트와 상세 목록 뷰어를 제공합니다.
*   **결과**: '주식', '흑백요리사' 등 다양한 키워드에 대해 수집된 실절적인 트렌드 리포트와 시각화 툴을 얻을 수 있습니다.

### 📂 [2026-01-07 AM] 서울 지하철 실시간 데이터 적재 연구
*   **프로젝트 위치**: `studying/seoul_subway_monitoring/`
*   **목적**: 서울시 공공데이터 API와 Supabase(PostgreSQL) 클라우드 DB 연동의 기초 기술을 실습하고 데이터 스키마를 설계합니다.
*   **동작 원리 및 순서**:
    1.  **API 연동 (`ingest_subway.py`)**: 서울 열린데이터 광장의 실시간 열차 위치 API를 호출하여 JSON 데이터를 수신합니다.
    2.  **스키마 정의 (`schema.sql`)**: 수집된 정보의 효율적인 저장을 위해 초기 테이블 구조를 설계하고 인덱스를 구성합니다.
    3.  **검증 (`analysis_notebook.ipynb`)**: Jupyter Notebook을 통해 적재된 초기 데이터의 정합성을 확인합니다.
*   **결과**: 외부 API 데이터를 클린한 데이터베이스 형태로 구조화하여 적재하는 파이프라인 기초를 확보했습니다.

### 📂 [2026-01-07 PM] 서울 지하철 실시간 모니터링 & 분석 시스템 (고도화)
*   **프로젝트 위치**: `subway/seoul-subway-monitor/`
*   **목적**: 1~9호선 실시간 열차 위치 데이터를 전수 수집하여 배차 간격, 지연 구간, 회차 효율성 등 운영 지표를 도출하는 전문 모니터링 시스템입니다.
*   **동작 원리 및 순서**:
    1.  **배치 스케줄링 (`src/main.py`)**: `schedule` 라이브러리를 활용하여 1분 주기로 자동화된 수집 엔진을 상시 가동합니다.
    2.  **모듈형 API 클라이언트 (`src/api_client.py`)**: OOP 기반 설계로 서울시 API 호출 및 예외 처리를 담당하며, 대량의 데이터를 안정적으로 수집합니다.
    3.  **DB 최적화 (`src/db_client.py`)**: 수집된 데이터를 직관적인 영문 컬럼명으로 변환하고 Supabase에 실시간 Upsert 처리합니다.
    4.  **핵심 지표 분석 (`src/analysis/`)**:
        *   `dwell_time.py`: 역별 실제 정차 시간을 측정하여 지연 핫스팟 탐지.
        *   `interval_analysis.py`: 열차 간 간격을 분석하여 배차 정기성 확인.
        *   `turnaround_efficiency.py`: 종착역 회차 소요 시간을 분석하여 병목 지점 도출.
*   **결과**: 정적인 데이터를 넘어 '운영 효율성'을 실시간으로 추적할 수 있는 엔지니어링 기반의 지하철 대시보드 인프라를 구축했습니다.

### 📂 [2026-01-08] YouTube Viral Radar (YVR) - 고도화 v2.5
*   **프로젝트 위치**: `solo_project/youtube_viral/`
*   **목적**: YouTube API 할당량(Quota)을 최소화하면서도, 실시간 트렌드 키워드를 포착하고 그 '파워'와 '신선도'를 분석하는 Snapshot Analysis 시스템입니다.
*   **동작 원리 및 순서**:
    1.  **트렌드 키워드 추출 (`src/processor.py`)**: 인기 급상승 영상 300개를 시드로 삼아, 카테고리별 분산 추출(Round-Robin) 전략을 통해 전 분야의 핵심 키워드를 공정하게 선발합니다.
    2.  **스냅샷 분석 (`src/analyzer.py`)**: 선발된 키워드별로 검색 결과 50개를 분석하여 '시간당 조회수(Power)', '신규 업로드 비중(Density)', '점유율(Share)'을 계산합니다.
    3.  **데이터 시각화 (`src/visualizer.py`)**: 분석된 수치들을 기반으로 Chart.js를 활용한 프리미엄 다크 모드 대시보드(`dashboard.html`)를 자동 생성합니다.
    4.  **알림 및 적재**: 분석 결과는 Supabase에 기록되며, 특정 임계치(Surge/Power)를 넘을 경우 슬랙/디스코드로 즉시 알림을 전송합니다.
*   **결과**: 할당량 80% 절감과 동시에 전 분야에 걸친 객관적인 바이럴 트렌드 통찰력을 실시간으로 제공합니다.

### 📂 [2026-01-14] 네이버 블로그 검색 데이터 수집 시스템
*   **프로젝트 위치**: `naver_crawling/`, `jw_naver_crawling/`
*   **목적**: 네이버 Search API를 통해 특정 키워드에 대한 일별 블로그 게시글 수를 정기적으로 수집하여 트렌드 지표로 활용합니다.
*   **동작 원리**: 
    1.  **API 호출**: 네이버 오픈 API를 연동하여 특정 날짜 범위의 검색 결과 총량을 조회합니다.
    2.  **데이터 적재**: 수집된 키워드별 일별 카운트를 Supabase DB에 적재하여 시계열 데이터를 형성합니다.
*   **결과**: 관심 키워드의 온라인 노출 빈도 변화를 수치화하여 객관적인 트렌드 분석이 가능해졌습니다.

### 📂 [2026-01-16] 마라샹궈 & 포켓몬 테마 데이터 수집 엔진
*   **프로젝트 위치**: `mara_crawling/`, `pokemon_crawling/`
*   **목적**: 특정 카테고리(음식, 캐릭터)에 특화된 크롤링 파이프라인을 구축하고 대량의 데이터를 안정적으로 수집합니다.
*   **동작 원리**: 
    1.  **키워드 최적화**: 분석 대상이 되는 연관 키워드 세트를 구성합니다.
    2.  **자동화 스크립트**: 반복적인 API 요청 및 예외 처리를 자동화하여 무중단 데이터 수집을 수행합니다.
*   **결과**: 특정 도메인에 대한 심층적인 트렌드 분석을 위한 데이터 원천을 확보했습니다.

### 📂 [2026-01-20] YouTube 일일 트렌드 분석 시스템 (v3.0)
*   **프로젝트 위치**: `youtube_crawling/`
*   **목적**: 특정 키워드에 대해 실시간으로 화제가 되는 영상들의 메트릭을 수집하여 시장의 반응 속도를 분석합니다.
*   **동작 원리**: 
    1.  **데일리 클리핑**: 전날 업로드된 영상을 타겟팅하여 조회수, 좋아요, 댓글 수 등 핵심 메트릭을 수집합니다.
    2.  **성능 분석**: 수집된 메트릭을 기반으로 영상의 화제성을 수치화합니다.
*   **결과**: 매일 업데이트되는 YouTube 시장의 변화를 가장 빠르게 포착할 수 있는 환경을 구축했습니다.

### 📂 [2026-01-23] YouTube 누적 성장 추적 및 자동화 시스템 (최종 완성)
*   **프로젝트 위치**: `youtube_trend_tracker/`
*   **목적**: 과거 영상의 **누적 성장 데이터**를 매일 추적하고, 인프라 비용과 관리 공수를 최소화한 완전 자동화 시스템입니다.
*   **동작 원리**: 
    1.  **API 키 자동 로테이션**: YouTube API 쿼타 한도를 넘을 경우 등록된 여러 키로 자동 스위칭하여 대규모 수집을 지속합니다.
    2.  **시계열 누적 관리**: 동일 영상 세트의 메트릭을 일별로 업데이트하여 '증가량' 및 '증가율'을 매일 계산/적재합니다.
    3.  **GitHub Actions 자동화**: 클라우드 서버 없이 GitHub Actions를 활용해 매일 오전 9시 정기 수집을 수행합니다.
*   **결과**: 9월부터 현재까지 144일치 데이터를 완벽 적재했으며, 수동 개입 없는 영구적 트렌드 모니터링 체계를 완성했습니다.

---

## 🛠️ 기술 스택 (Tech Stack)
*   **Language**: Python 3.12+
*   **Database**: Supabase (PostgreSQL)
*   **Automation**: GitHub Actions, macOS Cron
*   **Libraries**: Pandas, Requests, Supabase-py, Matplotlib, Google-api-python-client, Dotenv, Tqdm
