import os
import pandas as pd
from googleapiclient.discovery import build
from dotenv import load_dotenv
from datetime import datetime, timedelta, timezone, date
import sys
import io
from pathlib import Path
from src.database import TrendDatabase
import time

# í™˜ê²½ ì„¤ì • - config/.env íŒŒì¼ ë¡œë“œ
config_path = Path(__file__).parent.parent / 'config' / '.env'
load_dotenv(dotenv_path=config_path)

# í•œê¸€ ì¶œë ¥ ê¹¨ì§ ë°©ì§€
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

class AdvancedTrendTracker:
    """YouTube íŠ¸ë Œë“œ ì¶”ì  í¬ë¡¤ëŸ¬ (API í‚¤ ìë™ ì „í™˜ ê¸°ëŠ¥ í¬í•¨)"""
    
    def __init__(self):
        # ì—¬ëŸ¬ API í‚¤ ë¡œë“œ
        self.api_keys = []
        key_index = 1
        while True:
            key = os.getenv(f"YOUTUBE_API_KEY_{key_index}")
            if not key:
                break
            self.api_keys.append(key)
            key_index += 1
        
        if not self.api_keys:
            raise ValueError("[!] YOUTUBE_API_KEY_1ì´ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")
        
        self.current_key_index = 0
        self.exhausted_keys = set() # ì‹¤íŒ¨í•œ í‚¤ ì¸ë±ìŠ¤ ì¶”ì 
        self.youtube = build("youtube", "v3", developerKey=self.api_keys[self.current_key_index])
        self.db = TrendDatabase()
        
        print(f"[âœ“] YouTube API ì—°ê²° ì„±ê³µ (ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {len(self.api_keys)}ê°œ)")

    def switch_api_key(self):
        """ë‹¤ìŒ API í‚¤ë¡œ ì „í™˜"""
        self.exhausted_keys.add(self.current_key_index)
        
        if len(self.exhausted_keys) >= len(self.api_keys):
            print("[!] ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
        
        # ì•„ì§ ì‹œë„í•´ë³´ì§€ ì•Šì€ í‚¤ë¥¼ ì°¾ì•„ì„œ ì „í™˜
        start_index = self.current_key_index
        for _ in range(len(self.api_keys)):
            self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
            if self.current_key_index not in self.exhausted_keys:
                self.youtube = build("youtube", "v3", developerKey=self.api_keys[self.current_key_index])
                print(f"[ğŸ”„] API í‚¤ ì „í™˜ ì™„ë£Œ (í‚¤ #{self.current_key_index + 1})")
                return True
        
        return False

    def search_videos_by_time_range(self, keyword, start_time, end_time, retry_count=0, depth=0):
        """
        íŠ¹ì • ì‹œê°„ ë²”ìœ„ì— ì—…ë¡œë“œëœ ì˜ìƒ ê²€ìƒ‰ (ì¬ê·€ì  ì‹œê°„ ë¶„í•  í¬í•¨)
        
        Args:
            keyword (str): ê²€ìƒ‰ í‚¤ì›Œë“œ
            start_time (datetime): ì‹œì‘ ì‹œê°„ (UTC)
            end_time (datetime): ì¢…ë£Œ ì‹œê°„ (UTC)
            retry_count (int): ì¬ì‹œë„ íšŸìˆ˜
            depth (int): ì¬ê·€ ê¹Šì´
            
        Returns:
            list: ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        start_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        end_str = end_time.strftime('%Y-%m-%dT%H:%M:%SZ')
        
        videos = []
        next_page_token = None
        page_count = 0
        max_pages = 20  # ìµœëŒ€ 20í˜ì´ì§€ (1000ê°œ ì œí•œ)
        
        try:
            while True:
                # ê²€ìƒ‰ API í˜¸ì¶œ
                search_response = self.youtube.search().list(
                    q=keyword,
                    part="id,snippet",
                    publishedAfter=start_str,
                    publishedBefore=end_str,
                    maxResults=50,
                    type="video",
                    order="date",
                    regionCode="KR",
                    relevanceLanguage="ko",
                    pageToken=next_page_token
                ).execute()

                items = search_response.get("items", [])
                if not items:
                    break

                # ì˜ìƒ ID ì¶”ì¶œ
                video_ids = [item["id"]["videoId"] for item in items]
                
                # ìƒì„¸ ì •ë³´ ì¡°íšŒ
                stats_response = self.youtube.videos().list(
                    part="statistics,snippet",
                    id=",".join(video_ids)
                ).execute()

                # í†µê³„ ìˆ˜ì§‘
                for item in stats_response.get("items", []):
                    stats = item["statistics"]
                    videos.append({
                        "video_id": item["id"],
                        "title": item["snippet"]["title"],
                        "views": int(stats.get("viewCount", 0)),
                        "likes": int(stats.get("likeCount", 0)),
                        "comments": int(stats.get("commentCount", 0))
                    })

                # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                next_page_token = search_response.get("nextPageToken")
                page_count += 1
                
                # í˜ì´ì§€ ì œí•œì— ë„ë‹¬í•˜ë©´ ì‹œê°„ ë²”ìœ„ë¥¼ ë¶„í• 
                if page_count >= max_pages and next_page_token:
                    if depth < 3:  # ìµœëŒ€ 3ë‹¨ê³„ê¹Œì§€ ë¶„í•  (6ì‹œê°„ -> 3ì‹œê°„ -> 1.5ì‹œê°„)
                        print(f"  âš ï¸  ê²°ê³¼ê°€ ë§ì•„ ì‹œê°„ ë²”ìœ„ë¥¼ ë¶„í• í•©ë‹ˆë‹¤ (ê¹Šì´: {depth+1})")
                        
                        # ì‹œê°„ ë²”ìœ„ë¥¼ ë°˜ìœ¼ë¡œ ë¶„í• 
                        mid_time = start_time + (end_time - start_time) / 2
                        
                        # ì „ë°˜ë¶€ ê²€ìƒ‰
                        videos_first = self.search_videos_by_time_range(
                            keyword, start_time, mid_time, retry_count, depth + 1
                        )
                        time.sleep(0.5)
                        
                        # í›„ë°˜ë¶€ ê²€ìƒ‰
                        videos_second = self.search_videos_by_time_range(
                            keyword, mid_time, end_time, retry_count, depth + 1
                        )
                        
                        # ì¤‘ë³µ ì œê±° í›„ ë³‘í•©
                        all_videos = videos + videos_first + videos_second
                        seen_ids = set()
                        unique_videos = []
                        for v in all_videos:
                            if v['video_id'] not in seen_ids:
                                seen_ids.add(v['video_id'])
                                unique_videos.append(v)
                        
                        return unique_videos
                    else:
                        print(f"  âš ï¸  ìµœëŒ€ ë¶„í•  ê¹Šì´ ë„ë‹¬, ì¼ë¶€ ì˜ìƒì´ ëˆ„ë½ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                        break
                
                if not next_page_token:
                    break
                    
                # API í˜¸ì¶œ ì œí•œ ë°©ì§€
                time.sleep(0.5)
                
        except Exception as e:
            if "quotaExceeded" in str(e):
                print(f"[!] API í• ë‹¹ëŸ‰ ì´ˆê³¼ (í‚¤ #{self.current_key_index + 1})")
                
                # API í‚¤ ì „í™˜ ì‹œë„
                if retry_count < len(self.api_keys) - 1:
                    if self.switch_api_key():
                        print(f"[â†»] ì¬ì‹œë„ ì¤‘...")
                        time.sleep(1)
                        return self.search_videos_by_time_range(
                            keyword, start_time, end_time, retry_count + 1, depth
                        )
                
                print(f"[!] ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                raise
            else:
                print(f"[!] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return videos

    def search_videos_by_upload_date(self, keyword, upload_date, retry_count=0):
        """
        íŠ¹ì • ë‚ ì§œì— ì—…ë¡œë“œëœ ì˜ìƒ ê²€ìƒ‰ (6ì‹œê°„ ë‹¨ìœ„ë¡œ ë¶„í• )
        
        Args:
            keyword (str): ê²€ìƒ‰ í‚¤ì›Œë“œ
            upload_date (date): ì—…ë¡œë“œ ë‚ ì§œ
            retry_count (int): ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            list: ì˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        all_videos = []
        
        # í•˜ë£¨ë¥¼ 6ì‹œê°„ì”© 4ê°œ êµ¬ê°„ìœ¼ë¡œ ë¶„í• 
        time_ranges = [
            (0, 6),   # 00:00 - 06:00
            (6, 12),  # 06:00 - 12:00
            (12, 18), # 12:00 - 18:00
            (18, None)  # 18:00 - ë‹¤ìŒë‚  00:00
        ]
        
        for start_hour, end_hour in time_ranges:
            start_time = datetime.combine(upload_date, datetime.min.time()).replace(
                hour=start_hour, tzinfo=timezone.utc
            )
            
            # ë§ˆì§€ë§‰ êµ¬ê°„ì€ ë‹¤ìŒ ë‚  00:00ìœ¼ë¡œ ì„¤ì •
            if end_hour is None:
                end_time = datetime.combine(upload_date + timedelta(days=1), datetime.min.time()).replace(
                    tzinfo=timezone.utc
                )
            else:
                end_time = datetime.combine(upload_date, datetime.min.time()).replace(
                    hour=end_hour, tzinfo=timezone.utc
                )
            
            videos = self.search_videos_by_time_range(keyword, start_time, end_time, retry_count)
            all_videos.extend(videos)
            
            time.sleep(0.3)  # êµ¬ê°„ ì‚¬ì´ ëŒ€ê¸°
        
        # ì¤‘ë³µ ì œê±°
        seen_ids = set()
        unique_videos = []
        for v in all_videos:
            if v['video_id'] not in seen_ids:
                seen_ids.add(v['video_id'])
                unique_videos.append(v)
        
        return unique_videos

    def calculate_growth(self, current_stats, previous_stats):
        """
        ì¦ê°€ëŸ‰ ë° ì¦ê°€ìœ¨ ê³„ì‚°
        
        Args:
            current_stats (dict): í˜„ì¬ í†µê³„
            previous_stats (dict or None): ì „ë‚  í†µê³„
            
        Returns:
            dict: ì¦ê°€ëŸ‰ ë° ì¦ê°€ìœ¨ ì •ë³´
        """
        if not previous_stats:
            return {
                'views_growth': 0,
                'likes_growth': 0,
                'comments_growth': 0,
                'views_growth_rate': 0.0,
                'likes_growth_rate': 0.0,
                'comments_growth_rate': 0.0
            }
        
        views_growth = current_stats['total_views'] - previous_stats['total_views']
        likes_growth = current_stats['total_likes'] - previous_stats['total_likes']
        comments_growth = current_stats['total_comments'] - previous_stats['total_comments']
        
        # ì¦ê°€ìœ¨ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        views_growth_rate = (views_growth / previous_stats['total_views'] * 100) if previous_stats['total_views'] > 0 else 0
        likes_growth_rate = (likes_growth / previous_stats['total_likes'] * 100) if previous_stats['total_likes'] > 0 else 0
        comments_growth_rate = (comments_growth / previous_stats['total_comments'] * 100) if previous_stats['total_comments'] > 0 else 0
        
        return {
            'views_growth': views_growth,
            'likes_growth': likes_growth,
            'comments_growth': comments_growth,
            'views_growth_rate': round(views_growth_rate, 2),
            'likes_growth_rate': round(likes_growth_rate, 2),
            'comments_growth_rate': round(comments_growth_rate, 2)
        }

    def track_date_range(self, keyword, start_date, end_date):
        """
        íŠ¹ì • ë‚ ì§œ ë²”ìœ„ì˜ ì˜ìƒë“¤ì˜ í˜„ì¬ í†µê³„ ìˆ˜ì§‘ ë° ì €ì¥

        ìµœì í™” ë°©ì‹:
          1ë‹¨ê³„: ì¼ë³„ ë£¨í”„ë¡œ ê²€ìƒ‰ (6ì‹œê°„ ë¶„í• /ì¬ê·€ ì—†ì´ ë‹¨ìˆœ í˜ì´ì§•)
                 â†’ ì¼ë³„ 40~60ê°œ ì˜ìƒë„ ëˆ„ë½ ì—†ì´ ìˆ˜ì§‘
          2ë‹¨ê³„: ì „ì²´ ì˜ìƒ IDë¥¼ 50ê°œì”© ë°°ì¹˜ë¡œ í†µê³„ ì¡°íšŒ
          3ë‹¨ê³„: ì—…ë¡œë“œ ë‚ ì§œë³„ ì§‘ê³„ í›„ DB ì €ì¥

        Args:
            keyword (str): ê²€ìƒ‰ í‚¤ì›Œë“œ
            start_date (date): ì‹œì‘ ë‚ ì§œ (í¬í•¨)
            end_date (date): ì¢…ë£Œ ë‚ ì§œ (í¬í•¨)
        """
        from collections import defaultdict
        
        # ìˆ˜ì§‘ ì‹œì‘ ì‹œ ì†Œì§„ëœ í‚¤ ëª©ë¡ ì´ˆê¸°í™” (ì˜¤ëŠ˜ì˜ í• ë‹¹ëŸ‰ í™•ì¸ì„ ìœ„í•´)
        self.exhausted_keys = set()
        
        collected_date = date.today()
        total_days = (end_date - start_date).days + 1
        api_call_count = 0

        print(f"\n{'='*60}")
        print(f"[*] íŠ¸ë Œë“œ ì¶”ì  ì‹œì‘ (ìµœì í™” ëª¨ë“œ)")
        print(f"    í‚¤ì›Œë“œ: {keyword}")
        print(f"    ìˆ˜ì§‘ ë‚ ì§œ: {collected_date}")
        print(f"    ìˆ˜ì§‘ ë²”ìœ„: {start_date} ~ {end_date} ({total_days}ì¼)")
        print(f"    ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤: {len(self.api_keys)}ê°œ")
        print(f"{'='*60}\n")

        # â”€â”€ Step 1: ì¼ë³„ ë£¨í”„ë¡œ ê²€ìƒ‰ (ë‹¨ìˆœ í˜ì´ì§•ë§Œ, 6ì‹œê°„ ë¶„í•  ì—†ìŒ) â”€â”€
        #   ì¼ë³„ 40~60ê°œ ì˜ìƒ â†’ í˜ì´ì§€ 1~2íšŒë©´ ì¶©ë¶„ (500ê°œ ì œí•œ ì•ˆì „)
        print("[1/3] ì¼ë³„ ì˜ìƒ ëª©ë¡ ê²€ìƒ‰ ì¤‘...")

        all_video_ids = []
        video_publish_dates = {}  # video_id -> "YYYY-MM-DD"

        current_date = start_date
        day_num = 1

        while current_date <= end_date:
            day_start_str = datetime.combine(current_date, datetime.min.time()).replace(
                tzinfo=timezone.utc
            ).strftime('%Y-%m-%dT%H:%M:%SZ')
            day_end_str = (datetime.combine(current_date + timedelta(days=1), datetime.min.time()).replace(
                tzinfo=timezone.utc
            ) - timedelta(seconds=1)).strftime('%Y-%m-%dT%H:%M:%SZ')

            next_page_token = None
            day_count = 0

            while True:
                try:
                    search_response = self.youtube.search().list(
                        q=keyword,
                        part="id,snippet",
                        publishedAfter=day_start_str,
                        publishedBefore=day_end_str,
                        maxResults=50,
                        type="video",
                        order="date",
                        regionCode="KR",
                        relevanceLanguage="ko",
                        pageToken=next_page_token
                    ).execute()
                    api_call_count += 1

                    items = search_response.get("items", [])
                    if not items:
                        break

                    for item in items:
                        vid = item["id"]["videoId"]
                        published = item["snippet"]["publishedAt"][:10]
                        if vid not in video_publish_dates:
                            all_video_ids.append(vid)
                            video_publish_dates[vid] = published
                            day_count += 1

                    next_page_token = search_response.get("nextPageToken")
                    if not next_page_token:
                        break

                    time.sleep(0.3)

                except Exception as e:
                    if "quotaExceeded" in str(e):
                        print(f"[!] API í• ë‹¹ëŸ‰ ì´ˆê³¼ (í‚¤ #{self.current_key_index + 1})")
                        if not self.switch_api_key():
                            print(f"[!] ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            print(f"[!] {current_date}ë¶€í„° ë‚´ì¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
                            raise
                        continue
                    raise

            if day_count > 0:
                print(f"  [{day_num}/{total_days}] {current_date}: {day_count}ê°œ ì˜ìƒ")
            else:
                print(f"  [{day_num}/{total_days}] {current_date}: ì˜ìƒ ì—†ìŒ")

            current_date += timedelta(days=1)
            day_num += 1
            time.sleep(0.2)

        print(f"  âœ“ ê²€ìƒ‰ ì™„ë£Œ: ì´ {len(all_video_ids)}ê°œ ì˜ìƒ (API {api_call_count}íšŒ)")

        if not all_video_ids:
            print("[!] ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # â”€â”€ Step 2: ì „ì²´ ì˜ìƒ IDë¥¼ ë°°ì¹˜ë¡œ í†µê³„ ì¡°íšŒ (50ê°œì”©) â”€â”€
        print(f"\n[2/3] ì˜ìƒ í†µê³„ ì¼ê´„ ì¡°íšŒ ì¤‘ ({len(all_video_ids)}ê°œ)...")

        all_videos = []
        stats_call_count = 0

        for i in range(0, len(all_video_ids), 50):
            batch_ids = all_video_ids[i:i+50]

            try:
                stats_response = self.youtube.videos().list(
                    part="statistics",
                    id=",".join(batch_ids)
                ).execute()
                api_call_count += 1
                stats_call_count += 1

                for item in stats_response.get("items", []):
                    stats = item["statistics"]
                    vid = item["id"]
                    all_videos.append({
                        "video_id": vid,
                        "upload_date": video_publish_dates.get(vid, "unknown"),
                        "views": int(stats.get("viewCount", 0)),
                        "likes": int(stats.get("likeCount", 0)),
                        "comments": int(stats.get("commentCount", 0))
                    })

            except Exception as e:
                if "quotaExceeded" in str(e):
                    print(f"[!] API í• ë‹¹ëŸ‰ ì´ˆê³¼ (í‚¤ #{self.current_key_index + 1})")
                    if not self.switch_api_key():
                        print(f"[!] ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        raise
                    continue
                print(f"  â†’ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")

            print(f"  â†’ {min(i+50, len(all_video_ids))}/{len(all_video_ids)} ì²˜ë¦¬ ì™„ë£Œ")
            time.sleep(0.3)

        print(f"  âœ“ í†µê³„ ì¡°íšŒ ì™„ë£Œ (API {stats_call_count}íšŒ)")

        # â”€â”€ Step 3: ì—…ë¡œë“œ ë‚ ì§œë³„ ì§‘ê³„ ë° ì €ì¥ â”€â”€
        print(f"\n[3/3] ë‚ ì§œë³„ ì§‘ê³„ ë° ì €ì¥ ì¤‘...")

        date_groups = defaultdict(list)
        for video in all_videos:
            date_groups[video['upload_date']].append(video)

        success_count = 0
        error_count = 0

        for upload_date_str in sorted(date_groups.keys()):
            videos = date_groups[upload_date_str]

            try:
                upload_dt = date.fromisoformat(upload_date_str)
            except ValueError:
                print(f"  â†’ ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {upload_date_str}, ê±´ë„ˆëœ€")
                error_count += 1
                continue

            current_stats = {
                'keyword': keyword,
                'upload_date': upload_dt,
                'collected_date': collected_date,
                'video_count': len(videos),
                'total_views': sum(v['views'] for v in videos),
                'total_likes': sum(v['likes'] for v in videos),
                'total_comments': sum(v['comments'] for v in videos)
            }

            # ì „ë‚  ë°ì´í„° ì¡°íšŒ
            previous_data = self.db.get_previous_day_data(
                keyword, upload_dt, collected_date
            )

            # ì¦ê°€ëŸ‰ ê³„ì‚°
            growth_data = self.calculate_growth(current_stats, previous_data)
            current_stats.update(growth_data)

            # DB ì €ì¥ (ê¸°ì¡´ ë°ì´í„°ì™€ video_count ë¹„êµ)
            existing_data = self.db.get_current_data(keyword, upload_dt, collected_date)
            
            if existing_data:
                old_count = existing_data.get('video_count', 0)
                if old_count > current_stats['video_count']:
                    print(f"  â†’ [{upload_date_str}] ê±´ë„ˆëœ€: ê¸°ì¡´ ë°ì´í„°ì˜ ì˜ìƒ ìˆ˜({old_count}ê°œ)ê°€ í˜„ì¬({current_stats['video_count']}ê°œ)ë³´ë‹¤ ë§ìŒ")
                    continue
                else:
                    print(f"  â†’ [{upload_date_str}] ì—…ë°ì´íŠ¸: ê¸°ì¡´({old_count}ê°œ) -> í˜„ì¬({current_stats['video_count']}ê°œ)")

            # DB ì €ì¥
            self.db.save_trend_data(current_stats)
            success_count += 1

            # ì¦ê°€ëŸ‰ í‘œì‹œ
            if previous_data:
                print(f"  [{upload_date_str}] ì˜ìƒ: {len(videos)}ê°œ | "
                      f"ì¡°íšŒìˆ˜: {current_stats['total_views']:,} "
                      f"(+{growth_data['views_growth']:,}, {growth_data['views_growth_rate']:+.1f}%)")
            else:
                print(f"  [{upload_date_str}] ì˜ìƒ: {len(videos)}ê°œ | "
                      f"ì¡°íšŒìˆ˜: {current_stats['total_views']:,} (ì²« ìˆ˜ì§‘)")

        print(f"\n{'='*60}")
        print(f"[âœ“] íŠ¸ë Œë“œ ì¶”ì  ì™„ë£Œ")
        print(f"    ê²€ìƒ‰ëœ ì˜ìƒ: {len(all_videos)}ê°œ")
        print(f"    ì €ì¥ëœ ë‚ ì§œ: {success_count}ì¼")
        print(f"    ì˜¤ë¥˜: {error_count}ì¼")
        print(f"    ì´ API í˜¸ì¶œ: {api_call_count}íšŒ")
        print(f"{'='*60}\n")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        tracker = AdvancedTrendTracker()
        
        # ì„¤ì •
        keyword = "ì„ì„±ê·¼ ì‰í”„"
        lookback_days = 30  # ê¸°ë³¸ê°’
        
        # íŠ¸ë Œë“œ ì¶”ì  ì‹¤í–‰
        today = date.today()
        start_date = today - timedelta(days=lookback_days)
        tracker.track_date_range(keyword, start_date, today - timedelta(days=1))
        
    except Exception as e:
        print(f"[!] ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()
