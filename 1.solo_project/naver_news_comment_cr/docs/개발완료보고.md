# 네이버 뉴스 댓글 크롤링 프로젝트 개발 완료 보고

## ✅ 개발 완료 항목

### 1. 프로젝트 구조 생성
```
naver_news_comment_cr/
├── config/                      # 환경 설정
│   ├── __init__.py
│   ├── .env.example            # 환경 변수 템플릿
│   └── settings.py             # 설정 로드 모듈
├── database/                    # 데이터베이스
│   ├── __init__.py
│   ├── schema.sql              # Supabase 테이블 스키마
│   └── supabase_manager.py     # DB CRUD 관리
├── src/                         # 소스 코드
│   ├── __init__.py
│   ├── collector/              # 수집 모듈
│   │   ├── __init__.py
│   │   ├── news_searcher.py   # 뉴스 검색 (API/크롤링)
│   │   └── comment_crawler.py # 댓글 크롤링 (Selenium)
│   ├── analyzer/               # 분석 모듈 (향후 개발)
│   └── utils/                  # 유틸리티 (향후 개발)
├── scripts/                     # 실행 스크립트
│   └── collect_comments.py     # 메인 수집 스크립트
├── docs/                        # 문서
│   └── QUICKSTART.md           # 빠른 시작 가이드
├── .gitignore                   # Git 무시 파일
├── requirements.txt             # 패키지 의존성
├── README.md                    # 프로젝트 설명서
├── AGENT.md                     # 에이전트 가이드
└── 설계서.md                     # 설계 문서
```

### 2. 핵심 기능 구현

#### ✅ 뉴스 검색 (`news_searcher.py`)
- 네이버 검색 API 지원 (선택사항)
- BeautifulSoup 기반 웹 크롤링 (기본)
- 네이버 뉴스만 필터링
- 자동 fallback (API 실패 시 크롤링으로 전환)

#### ✅ 댓글 크롤링 (`comment_crawler.py`)
- Selenium 기반 동적 크롤링
- iframe 자동 처리
- 댓글 "더보기" 버튼 자동 클릭
- 작성자, 내용, 공감/비공감 수, 작성 시간 수집
- 고유 ID 자동 생성 (해시 기반)

#### ✅ 데이터베이스 관리 (`supabase_manager.py`)
- Supabase 연결 및 초기화
- 단일/배치 댓글 삽입
- 중복 체크 기능
- 뉴스별 댓글 조회

#### ✅ 메인 실행 스크립트 (`collect_comments.py`)
- 키워드 입력 → 뉴스 검색 → 댓글 수집 → DB 저장
- 중복 자동 필터링
- 진행 상황 실시간 출력
- 요청 간격 조절 (3초)

### 3. 데이터베이스 스키마

**테이블명**: `naver_news_comments`

| 필드 | 타입 | 설명 |
|------|------|------|
| comment_id | TEXT (PK) | 댓글 고유 ID |
| news_id | TEXT | 뉴스 기사 ID |
| author | TEXT | 작성자 |
| content | TEXT | 댓글 내용 |
| likes | INTEGER | 공감 수 |
| dislikes | INTEGER | 비공감 수 |
| published_at | TIMESTAMP | 작성 시간 |
| sentiment_label | INTEGER | BERT 분석 결과 (향후) |
| sentiment_score | FLOAT | 분석 확신도 (향후) |
| llm_sentiment | INTEGER | LLM 분석 결과 (향후) |
| keywords | TEXT[] | 키워드 리스트 (향후) |
| created_at | TIMESTAMP | 데이터 생성 시간 |

**인덱스**:
- `idx_news_id`: 뉴스별 조회 최적화
- `idx_sentiment_label`: 감성별 조회 최적화
- `idx_llm_sentiment`: LLM 분석 결과 조회 최적화
- `idx_published_at`: 시간순 조회 최적화

### 4. 기술 스택

- **Python 3.12**
- **BeautifulSoup4**: HTML 파싱 및 정적 크롤링
- **Selenium**: 동적 크롤링 (댓글 로딩)
- **Supabase**: PostgreSQL 기반 데이터베이스
- **python-dotenv**: 환경 변수 관리

## 🎯 주요 특징

1. **하이브리드 크롤링**: API 우선, 실패 시 자동으로 웹 크롤링 전환
2. **중복 방지**: 동일 댓글 자동 필터링
3. **안정성**: 에러 핸들링 및 재시도 로직
4. **확장성**: Opinion_Analysis 프로젝트와 DB 스키마 호환
5. **사용 편의성**: 간단한 키워드 입력으로 전체 프로세스 자동화

## 📝 사용 방법

### 1. 환경 설정
```bash
# 패키지 설치
pip install -r requirements.txt

# 환경 변수 설정
cp config/.env.example config/.env
# .env 파일에 Supabase 정보 입력

# Supabase 테이블 생성
# database/schema.sql 내용을 Supabase SQL Editor에서 실행
```

### 2. 실행
```bash
python scripts/collect_comments.py
```

### 3. 결과 확인
Supabase Dashboard → Table Editor → `naver_news_comments`

## 🔜 향후 개발 계획

### Phase 2: 텍스트 분석
- [ ] 맞춤법 교정 (et5-typos-corrector)
- [ ] 형태소 분석 (Konlpy)
- [ ] 키워드 추출

### Phase 3: 감성 분석
- [ ] BERT 기반 감성 분류
- [ ] LLM (DeepSeek) 정밀 분석
- [ ] 감성 점수 계산

### Phase 4: 시각화
- [ ] Streamlit 대시보드
- [ ] 워드클라우드
- [ ] 감성 트렌드 차트
- [ ] 뉴스별 여론 분석

### Phase 5: 자동화
- [ ] 스케줄링 (cron/APScheduler)
- [ ] 키워드 모니터링
- [ ] 알림 기능

## ⚠️ 주의사항

1. **크롤링 윤리**: 
   - 뉴스 간 3초 대기로 서버 부하 최소화
   - 과도한 요청 자제
   
2. **ChromeDriver**: 
   - Selenium 사용을 위해 필수 설치
   - Chrome 버전과 호환되는 버전 사용

3. **네이버 정책**: 
   - 일부 뉴스는 댓글 비활성화
   - 네이버 구조 변경 시 코드 수정 필요

4. **데이터 보관**: 
   - 개인정보 보호 고려
   - 작성자 정보는 마스킹된 ID만 저장

## 📊 테스트 결과

- ✅ 뉴스 검색: 정상 작동
- ✅ 댓글 크롤링: iframe 처리 완료
- ✅ DB 저장: Supabase 연동 완료
- ✅ 중복 체크: 정상 작동
- ✅ 에러 핸들링: 안정적

## 🎉 결론

네이버 뉴스 댓글 수집 시스템의 **Phase 1 (크롤링 및 DB 저장)** 개발이 완료되었습니다.

- 키워드 기반 뉴스 검색 ✅
- 동적 댓글 크롤링 ✅
- Supabase 자동 저장 ✅
- 중복 방지 ✅
- 사용자 친화적 인터페이스 ✅

다음 단계로 **감성 분석 및 키워드 추출** 기능을 개발할 준비가 완료되었습니다.
