# [Crawler Design] 한국 서브컬쳐 게임 데이터 크롤러 프로토타입 설계서

이 문서는 한국 서브컬쳐 게임 시장 데이터를 자동으로 수집하기 위한 크롤러의 기술적 스펙과 동작 로직을 정의합니다.

---

## 1. 기술 스택 (Tech Stack)

| 구분 | 기술 | 비고 |
| :--- | :--- | :--- |
| **언어** | Python 3.10+ | 데이터 처리 생산성 및 라이브러리 지원 |
| **동적 크롤링** | **Playwright** | 모바일인덱스 등 JS 렌더링이 필요한 사이트 대응 (Selenium보다 빠르고 안정적) |
| **정적 크롤링** | **BeautifulSoup4 / HTTPX** | 뉴스 및 커뮤니티 정적 페이지의 빠른 파싱 |
| **API 통신** | **Requests / HTTPX** | 네이버 데이터랩 및 구글 플레이 내부 API 호출 |
| **데이터 처리** | **Pandas** | 정규화 및 데이터 클렌징 |
| **DB 연동** | **supabase-py** | PostgreSQL 실시간 데이터 Upsert |

---

## 2. 주요 데이터 소스 및 추출 방법

### **A. 모바일 마켓 매출/순위 (주요 소스)**
- **대상**: 모바일인덱스(Mobile Index) 또는 구글 플레이 스토어 웹
- **추출 방법**: 
    - `Playwright`를 이용해 '매출 순위' 페이지 접속 후 데이터 로딩 대기.
    - 게임명, 순위 변동, 카테고리(롤플레잉 등) 정보 추출.
- **주기**: 매일 1회 (오전 06:00 권장)

### **B. 검색 트렌드 (네이버/구글)**
- **대상**: 네이버 데이터랩 (Naver DataLab API), 구글 트렌드 (Google Trends)
- **추출 방법**: 
    - 공식 API 또는 `pytrends` 라이브러리를 활용하여 특정 게임 키워드군(예: '블루 아카이브', 'Blue Archive')의 전일 검색 지수 획득.
- **주기**: 매일 1회

### **C. 유튜브 콘텐츠 동향 (여론 및 화제성)**
- **대상**: YouTube API v3
- **추출 방법**: 
    - **업로드 수**: 최근 24시간 내 특정 게임 관련 신규 영상 업로드 수 집계.
    - **인기 영상 지표**: 검색 결과 상위 영상의 조회수, 좋아요 수, 댓글 수(여론 분석용) 추출.
- **주기**: 매일 1회

### **D. 유저 여론 (커뮤니티)**
- **대상**: 아카라이브 서브컬쳐 게임 관련 채널 (예: 블루아카이브 채널)
- **추출 방법**: 
    - `BeautifulSoup`를 사용하여 인기글 제목 및 댓글 수 크롤링.
    - 게시글 본문의 키워드 빈도수를 분석하여 '긍정/부정' 지수 간이 측정.

---

## 3. 크롤러 동작 순서 (Operation Sequence)

1.  **환경 설정 (Initialize)**
    - Supabase API Key 및 네이버 API 클라이언트 정보 로드 (.env)
    - 브라우저 인스턴스(Playwright) 실행

2.  **데이터 수집 (Fetching Phase)**
    - **Step 1**: 구글 플레이/모바일인덱스에서 서브컬쳐 카테고리 랭킹 수집.
    - **Step 2**: 수집된 게임 리스트를 기반으로 네이버/구글 검색량 및 유튜브 데이터(업로드 수, 조회수 등) 수집.
    - **Step 3**: 주요 커뮤니티 및 유튜브 댓글 여론 수집.

3.  **데이터 정제 (Transformation Phase)**
    - 각기 다른 소스의 게임명을 통합 코드(Unique ID)로 매핑.
    - 매출 순위를 숫자형 데이터로 변환, 날짜 형식 표준화.

4.  **데이터 저장 (Loading Phase)**
    - `supabase.table().upsert()`를 사용하여 데이터 저장.
    - 중복 데이터 발생 시 기존 레코드 업데이트 (Integrity 유지).

5.  **예외 처리 및 알림 (Error Handling)**
    - 사이트 UI 변경 시 에러 로그 기록.
    - 데이터 유실 방지를 위한 파일(CSV) 백업본 생성.

---

## 4. 디렉토리 구조 (Proposed Structure)

```text
kr_subgame_crawling/
├── AGENT.md           # 본 설계서
├── main.py            # 크롤러 실행 엔트리 포인트
├── scrapers/          # 각 소스별 크롤링 모듈
│   ├── market.py      # 모바일인덱스/구글플레이
│   ├── trend.py       # 네이버/구글 검색 트렌드
│   ├── youtube.py     # 유튜브 API (조회수/댓글)
│   └── community.py   # 아카라이브/인벤
├── utils/             # 공통 유틸 (API 래퍼, 전처리)
│   ├── db.py          # Supabase 연동 코드
│   └── parser.py      # 데이터 정제 함수
└── .env               # 환경 변수 (비공개)
```

---

## 5. 단계별 개발 계획

- **Step 1**: Playwright 라이브러리 설정 및 구글 플레이 매출 순위 수집 프로토타입 개발.
- **Step 2**: 네이버 데이터랩 & Google Trends API 연동 및 유튜브 데이터 수집 모듈 개발.
- **Step 3**: Supabase DB 연동 및 수집 데이터(순위, 트렌드, 유튜브 지표) 자동 Insert 테스트.
- **Step 4**: 전체 프로세스를 통합한 `main.py` 구축.

---

**작성자**: Antigravity (Data Engineering Agent)
**생성일**: 2026-01-08
