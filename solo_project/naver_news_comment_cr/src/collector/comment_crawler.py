"""
ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ í¬ë¡¤ë§ ëª¨ë“ˆ
Seleniumì„ ì‚¬ìš©í•œ ë™ì  í¬ë¡¤ë§
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import hashlib
from typing import List, Dict, Optional
from datetime import datetime
from config.settings import MAX_COMMENTS_PER_NEWS


class NaverCommentCrawler:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ í¬ë¡¤ëŸ¬"""
    
    def __init__(self, headless: bool = True):
        """
        ì´ˆê¸°í™”
        
        Args:
            headless: í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
        """
        self.headless = headless
        self.driver = None
        print("âœ… ëŒ“ê¸€ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”")
    
    def _init_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”"""
        if self.driver:
            return
        
        chrome_options = Options()
        if self.headless:
            chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        print("âœ… Chrome ë“œë¼ì´ë²„ ì‹œì‘")
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            self.driver = None
            print("âœ… Chrome ë“œë¼ì´ë²„ ì¢…ë£Œ")
    
    def extract_news_id(self, url: str) -> Optional[str]:
        """
        ë‰´ìŠ¤ URLì—ì„œ ê¸°ì‚¬ ID ì¶”ì¶œ
        
        Args:
            url: ë„¤ì´ë²„ ë‰´ìŠ¤ URL
            
        Returns:
            ê¸°ì‚¬ ID (oid_aid í˜•ì‹)
        """
        try:
            # URL íŒŒë¼ë¯¸í„°ì—ì„œ oidì™€ aid ì¶”ì¶œ
            # ì˜ˆ: https://n.news.naver.com/article/001/0014123456
            # ë˜ëŠ” https://news.naver.com/main/read.naver?oid=001&aid=0014123456
            
            if '/article/' in url:
                # ìƒˆ í˜•ì‹
                parts = url.split('/article/')[-1].split('/')
                if len(parts) >= 2:
                    oid, aid = parts[0], parts[1].split('?')[0]
                    return f"{oid}_{aid}"
            elif 'oid=' in url and 'aid=' in url:
                # êµ¬ í˜•ì‹
                params = url.split('?')[-1].split('&')
                oid = aid = None
                for param in params:
                    if param.startswith('oid='):
                        oid = param.split('=')[1]
                    elif param.startswith('aid='):
                        aid = param.split('=')[1]
                if oid and aid:
                    return f"{oid}_{aid}"
            
            # ì¶”ì¶œ ì‹¤íŒ¨ì‹œ URL í•´ì‹œ ì‚¬ìš©
            return hashlib.md5(url.encode()).hexdigest()[:16]
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ ID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return hashlib.md5(url.encode()).hexdigest()[:16]
    
    def crawl_comments(self, news_url: str, max_comments: int = MAX_COMMENTS_PER_NEWS) -> List[Dict]:
        """
        íŠ¹ì • ë‰´ìŠ¤ì˜ ëŒ“ê¸€ í¬ë¡¤ë§
        
        Args:
            news_url: ë„¤ì´ë²„ ë‰´ìŠ¤ URL
            max_comments: ìµœëŒ€ ìˆ˜ì§‘ ëŒ“ê¸€ ìˆ˜
            
        Returns:
            ëŒ“ê¸€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        self._init_driver()
        
        news_id = self.extract_news_id(news_url)
        print(f"ğŸ“° ë‰´ìŠ¤ ID: {news_id}")
        
        try:
            # í˜ì´ì§€ ë¡œë“œ
            self.driver.get(news_url)
            time.sleep(2)
            
            # ëŒ“ê¸€ ì˜ì—­ìœ¼ë¡œ ìŠ¤í¬ë¡¤
            try:
                comment_section = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.ID, "cbox_module"))
                )
                self.driver.execute_script("arguments[0].scrollIntoView();", comment_section)
                time.sleep(1)
            except TimeoutException:
                print("âš ï¸  ëŒ“ê¸€ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (ëŒ“ê¸€ì´ ì—†ëŠ” ê¸°ì‚¬ì¼ ìˆ˜ ìˆìŒ)")
                return []
            
            # iframeìœ¼ë¡œ ì „í™˜ (ë„¤ì´ë²„ ëŒ“ê¸€ì€ iframe ë‚´ë¶€ì— ìˆìŒ)
            try:
                iframe = self.driver.find_element(By.ID, "cbox_module")
                self.driver.switch_to.frame(iframe)
                time.sleep(1)
            except NoSuchElementException:
                print("âš ï¸  ëŒ“ê¸€ iframeì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return []
            
            comments = []
            
            # ëŒ“ê¸€ ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ (ìµœëŒ€ ëŒ“ê¸€ ìˆ˜ê¹Œì§€)
            while len(comments) < max_comments:
                try:
                    # ë”ë³´ê¸° ë²„íŠ¼ ì°¾ê¸°
                    more_button = self.driver.find_element(By.CLASS_NAME, "u_cbox_btn_more")
                    if more_button.is_displayed():
                        more_button.click()
                        time.sleep(0.5)
                    else:
                        break
                except NoSuchElementException:
                    break
                except Exception as e:
                    print(f"âš ï¸  ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì¤‘ ì˜¤ë¥˜: {e}")
                    break
            
            # ëŒ“ê¸€ ìš”ì†Œ ìˆ˜ì§‘
            comment_elements = self.driver.find_elements(By.CLASS_NAME, "u_cbox_comment")
            
            for idx, elem in enumerate(comment_elements[:max_comments], 1):
                try:
                    comment_data = self._parse_comment_element(elem, news_id, idx)
                    if comment_data:
                        comments.append(comment_data)
                except Exception as e:
                    print(f"âš ï¸  ëŒ“ê¸€ íŒŒì‹± ì‹¤íŒ¨ (idx={idx}): {e}")
                    continue
            
            # iframeì—ì„œ ë‚˜ì˜¤ê¸°
            self.driver.switch_to.default_content()
            
            print(f"âœ… {len(comments)}ê°œ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ")
            return comments
            
        except Exception as e:
            print(f"âŒ ëŒ“ê¸€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []
    
    def _parse_comment_element(self, element, news_id: str, idx: int) -> Optional[Dict]:
        """
        ëŒ“ê¸€ ìš”ì†Œì—ì„œ ë°ì´í„° ì¶”ì¶œ
        
        Args:
            element: Selenium ì›¹ ìš”ì†Œ
            news_id: ë‰´ìŠ¤ ID
            idx: ëŒ“ê¸€ ì¸ë±ìŠ¤
            
        Returns:
            ëŒ“ê¸€ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì‘ì„±ì
            author_elem = element.find_element(By.CLASS_NAME, "u_cbox_nick")
            author = author_elem.text.strip()
            
            # ëŒ“ê¸€ ë‚´ìš©
            content_elem = element.find_element(By.CLASS_NAME, "u_cbox_contents")
            content = content_elem.text.strip()
            
            if not content:
                return None
            
            # ê³µê°/ë¹„ê³µê° ìˆ˜
            try:
                like_elem = element.find_element(By.CLASS_NAME, "u_cbox_cnt_recomm")
                likes = int(like_elem.text.strip() or 0)
            except:
                likes = 0
            
            try:
                dislike_elem = element.find_element(By.CLASS_NAME, "u_cbox_cnt_unrecomm")
                dislikes = int(dislike_elem.text.strip() or 0)
            except:
                dislikes = 0
            
            # ì‘ì„± ì‹œê°„
            try:
                time_elem = element.find_element(By.CLASS_NAME, "u_cbox_date")
                time_text = time_elem.text.strip()
                published_at = self._parse_datetime(time_text)
            except:
                published_at = datetime.now().isoformat()
            
            # ëŒ“ê¸€ ê³ ìœ  ID ìƒì„± (ë‰´ìŠ¤ID + ì‘ì„±ì + ë‚´ìš© í•´ì‹œ)
            comment_id = hashlib.md5(
                f"{news_id}_{author}_{content}_{idx}".encode()
            ).hexdigest()
            
            return {
                'comment_id': comment_id,
                'news_id': news_id,
                'author': author,
                'content': content,
                'likes': likes,
                'dislikes': dislikes,
                'published_at': published_at,
                'sentiment_label': None,
                'sentiment_score': None,
                'llm_sentiment': None,
                'keywords': None
            }
            
        except Exception as e:
            print(f"âŒ ëŒ“ê¸€ ìš”ì†Œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
    
    @staticmethod
    def _parse_datetime(time_text: str) -> str:
        """
        ë„¤ì´ë²„ ëŒ“ê¸€ ì‹œê°„ í…ìŠ¤íŠ¸ë¥¼ ISO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            time_text: "2ì‹œê°„ ì „", "2024.01.23. ì˜¤í›„ 2:30" ë“±
            
        Returns:
            ISO í˜•ì‹ ë‚ ì§œ ë¬¸ìì—´
        """
        try:
            # ê°„ë‹¨í•œ ì²˜ë¦¬: í˜„ì¬ ì‹œê°„ ë°˜í™˜ (ì¶”í›„ ì •ë°€í•œ íŒŒì‹± ì¶”ê°€ ê°€ëŠ¥)
            return datetime.now().isoformat()
        except:
            return datetime.now().isoformat()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    crawler = NaverCommentCrawler(headless=False)
    
    # í…ŒìŠ¤íŠ¸ìš© ë‰´ìŠ¤ URL (ì‹¤ì œ URLë¡œ êµì²´ í•„ìš”)
    test_url = "https://n.news.naver.com/article/001/0014123456"
    
    comments = crawler.crawl_comments(test_url, max_comments=10)
    
    for i, comment in enumerate(comments, 1):
        print(f"\n{i}. {comment['author']}: {comment['content'][:50]}...")
        print(f"   ê³µê°: {comment['likes']}, ë¹„ê³µê°: {comment['dislikes']}")
    
    crawler.close()
