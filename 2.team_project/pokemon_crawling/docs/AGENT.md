# [개발 구축서] 포켓몬 관련 블로그 검색 데이터 수집 시스템

## 1. 프로젝트 개요
- **목적**: 포켓몬스터 관련 키워드에 대한 네이버 블로그 검색 결과 수를 정기적으로 수집하여 트렌드 분석 지표로 활용.
- **핵심 지표**: 일별/키워드별 블로그 총 게시글 수 (Total Count).
- **대상 URL**: [네이버 블로그 검색 섹션](https://section.blog.naver.com/Search/Post.naver)

## 2. 기술 스택 및 환경
- **언어**: Python 3.10+
- **라이브러리**:
  - `requests`: HTTP 프로토콜을 통한 데이터 요청.
  - `BeautifulSoup4`: HTML/DOM 파싱.
  - `pandas`: 수집 데이터의 정량화 및 CSV/엑셀 저장.
  - `python-dotenv`: 환경 변수 관리 (필요 시 API 키나 경로 설정).
- **환경 구성**:
  - `User-Agent`: 실제 브라우저(Chrome/Edge) 헤더를 명시하여 봇 감지 방지.
  - `Time Delay`: 과도한 요청 방지를 위한 `time.sleep()` 적용.

## 3. 시스템 아키텍처 및 로직

### 3.1. 크롤링 매커니즘
- **수집 방식**: 네이버 블로그 검색 섹션은 JavaScript로 결과가 렌더링되는 구조입니다. `requests`를 사용할 경우, 실제 페이지를 렌더링하는 내부 API(JSON)를 타겟팅하거나, 응답 내부에 포함된 정적 데이터를 파싱합니다.
- **주요 타겟 (Selector)**: `em.search_number` (검색 결과 총 건수가 텍스트로 포함된 엘리먼트)
- **데이터 필터링**: 불필요한 광고/홍보성 글을 제외한 순수 '검색 결과 수' 추출에 집중.

### 3.2. 주요 기능 설계
1. **키워드 관리**: 수집 대상 키워드 리스트 관리.
2. **요청 파라미터 구성**: 검색어, 기간 설정(1일/1주일 등), 정렬 순서 파라미터화.
3. **데이터 전처리**: 문자열 형태의 숫자(예: "1,234건")를 정수형(Int)으로 변환.
4. **저장 시스템**: 수집 일시, 키워드, 결과 수를 기록하는 로컬 파일(CSV) 또는 DB 연동.

## 4. 상세 개발 단계 (Roadmap)

| 단계 | 작업 내용 | 비고 |
|:---:|:---|:---|
| **1단계** | **환경 설정** (`requirements.txt` 설치 및 프로젝트 구조 생성) | **완료** |
| **2단계** | **타겟 분석** (네이버 블로그 검색 결과 수 렌더링 영역 분석 및 선택자(Selector) 정의) | **완료** (`em.search_number`) |
| **3단계** | **크롤러 프로토타입 개발** (단일 키워드 기반 결과 수 수집 로직 구현) | **완료** (`test_api.py`) |
| **4단계** | **예외 처리 가동** (네트워크 에러, 검색 결과 없음 등에 대한 처리) | **완료** (JSON 파싱 및 HTTP 에러 처리) |
| **5단계** | **데이터 자동화** (다중 키워드 수집 및 일별 로그 저장 자동화) | **완료** (`crawler.py`) |

## 5. 정책 준수 및 고려사항
- **수집 주기**: 네이버 서비스 운영 정책에 반하지 않도록 과도한 빈도의 수집은 지양 (예: 1일 1회~수회 분산 수행).
- **데이터 활용 범위**: 상업적 재배포가 아닌 내부 분석용 지표로만 활용.
- **안정성**: `User-Agent`는 최신 브라우저 정보를 수시 업데이트하여 반영.

## 6. 기대 효과
- 특정 주제나 트렌드(예: 신제품, 사회 현상)에 대한 대중의 관심도를 수치화된 데이터로 확보.
- 향후 YouTube 등 타 플랫폼 데이터와 결합하여 통합 트렌드 인사이트 도출 가능.

